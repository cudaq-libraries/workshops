{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelization and scaling\n",
    "\n",
    "## Agenda\n",
    "\n",
    "### 1- Multi-QPU: parallel sampling and observe\n",
    "### 2- Hamiltonian Batching\n",
    "### 3- Multi-GPU and scaling\n",
    "### 4- Remote multi-QPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1- Multi-QPU: parallel sampling and observe\n",
    "\n",
    "In the multi-QPU mode (```mqpu``` option), the NVIDIA target provides a simulated QPU for every available NVIDIA GPU on the underlying system. Each QPU simulated via a ```cuStateVec``` simulator backend as defined by the NVIDIA target. This is useful for distributing separate quantum circuits.\n",
    "\n",
    "<div>\n",
    "<img src=\"./circuit-mqpu.png\" width=\"500\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Example with `sample` algorithmic primitives\n",
    "\n",
    "#### Hadamard test:\n",
    "\n",
    "<div>\n",
    "<img src=\"./hadamard-test.png\" width=\"600\">\n",
    "</div>\n",
    "\n",
    "\n",
    "Consider the observable $O$ and two generic quantum states $\\ket{\\psi}$ and $\\ket{\\phi}$. We want to calculate the quantity\n",
    "$$\n",
    "\\bra{\\psi} O \\ket{\\phi}.\n",
    "$$\n",
    "where $O$ is a Pauli operator.\n",
    "\n",
    "First of all we shall prepare the states $\\ket{\\psi}$ and $\\ket{\\phi}$ using a quantum circuit for each of them. So we  have\n",
    "$$\n",
    "\\ket{\\psi} = U_{\\psi}\\ket{0} \\qquad \\ket{\\phi} = U_{\\phi}\\ket{0}\n",
    "$$\n",
    "\n",
    "Let's define an observable we want to use:\n",
    "$$\n",
    "O = X_1X_2\n",
    "$$\n",
    "\n",
    "Now we can evaluate the matrix element using the following fact:\n",
    "$$\n",
    "\\bra{\\psi}O\\ket{\\phi} = \\bra{0}U_\\psi^\\dagger O U_\\phi\\ket{0}\n",
    "$$\n",
    "This is just an expectation value which can be solved with a simple Hadamard test. The probability to measure $0$ or $1$ in the ancilla qubit is\n",
    "\n",
    "$$\n",
    "P(0) = \\frac{1}{2} \\left[ I + Re \\bra{\\psi} O \\ket{\\phi} \\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(1) = \\frac{1}{2} \\left[ I - Re \\bra{\\psi} O \\ket{\\phi} \\right]\n",
    "$$\n",
    "\n",
    "The difference between the probability of $0$ and $1$ gives \n",
    "\n",
    "$$\n",
    "P(0)-P(1) = Re \\bra{\\psi} O \\ket{\\phi}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of QPUs: 5\n"
     ]
    }
   ],
   "source": [
    "import cudaq\n",
    "import numpy as np\n",
    "\n",
    "cudaq.set_target(\"nvidia\", option='mqpu')\n",
    "\n",
    "target = cudaq.get_target()\n",
    "qpu_count = target.num_qpus()\n",
    "print(\"Number of QPUs:\", qpu_count)\n",
    "\n",
    "@cudaq.kernel\n",
    "def U_psi(q:cudaq.qview, theta:float):\n",
    "    ry(theta, q[1])\n",
    "\n",
    "@cudaq.kernel\n",
    "def U_phi(q:cudaq.qview, theta: float):\n",
    "    rx(theta, q[0])\n",
    "\n",
    "@cudaq.kernel  \n",
    "def apply_pauli(q:cudaq.qview):\n",
    "    x(q[0])\n",
    "    x(q[1])\n",
    "\n",
    "@cudaq.kernel\n",
    "def kernel(n:int, angle:float, theta:float):\n",
    "    \n",
    "    ancilla = cudaq.qubit()\n",
    "    q = cudaq.qvector(n)\n",
    "    \n",
    "    h(ancilla)\n",
    "    \n",
    "    cudaq.control(U_phi, ancilla, q, theta)\n",
    "    cudaq.control(apply_pauli, ancilla, q)\n",
    "    cudaq.control(U_psi, ancilla, q, angle)\n",
    "    \n",
    "    h(ancilla)\n",
    "    \n",
    "    mz(ancilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "{ 0:49674 1:50326 }\n",
      "\n",
      "Observable QC:  -0.00652 + - 0.002236020448922594\n",
      "1\n",
      "{ 0:49704 1:50296 }\n",
      "\n",
      "Observable QC:  -0.00592 + - 0.002236028794090094\n",
      "2\n",
      "{ 0:49952 1:50048 }\n",
      "\n",
      "Observable QC:  -0.00096 + - 0.002236066947119428\n",
      "3\n",
      "{ 0:49942 1:50058 }\n",
      "\n",
      "Observable QC:  -0.00116 + - 0.0022360664730727486\n"
     ]
    }
   ],
   "source": [
    "shots = 100000  \n",
    "#angle = [0.0, 1.5,3.14,0.7]\n",
    "#theta = [0.6, 1.2 ,2.2 ,3.0]\n",
    "\n",
    "dim=4\n",
    "np.random.seed(42)\n",
    "angle = np.random.normal(0, 1, dim).tolist()\n",
    "theta= np.random.normal(0, 1, dim).tolist()\n",
    "\n",
    "qubit_num = 2\n",
    "\n",
    "result = []\n",
    "for i in range(4):  \n",
    "    count = cudaq.sample_async(kernel, qubit_num, angle[i], theta[i], shots_count = shots, qpu_id = i)  \n",
    "    result.append(count)  \n",
    "\n",
    "mean_val = np.zeros(len(angle))\n",
    "i = 0\n",
    "for count in result:\n",
    "    print(i)\n",
    "    i_result = count.get()\n",
    "    print(i_result)\n",
    "    mean_val[i] = (i_result['0'] - i_result['1']) / shots\n",
    "    error = np.sqrt(2 * i_result['0'] * i_result['1'] / shots) / shots\n",
    "    print('Observable QC: ',  mean_val[i],'+ -', error)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### Applications: Hadamrd test has been recently employed to predict drug toxicity; see this [paper](https://arxiv.org/pdf/2403.18997) to learn more\n",
    "\n",
    "<div>\n",
    "<img src=\"./drug-toxicity.png\" width=\"600\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Example with `observe` algorithmic primitives:\n",
    "\n",
    "#### Quantum neural network example:\n",
    "\n",
    "<div>\n",
    "<img src=\"./qnn-circ.png\" width=\"400\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of QPUs: 5\n",
      "Parameter shape:  (10000, 30)\n",
      "Elapsed time (s) for single GPU:  7.051674715010449\n",
      "We have 10000 parameters which we would like to execute\n",
      "We split this into 4 batches of 2500 , 2500 , 2500 , 2500\n",
      "Shape after splitting (2500, 30)\n",
      "Elapsed time (s) for multi-QPU with 5 QPUs is 1.812091946019791\n"
     ]
    }
   ],
   "source": [
    "import cudaq\n",
    "from cudaq import spin\n",
    "import numpy as np\n",
    "\n",
    "import timeit\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "cudaq.set_target(\"nvidia\", option=\"mqpu\")\n",
    "target = cudaq.get_target()\n",
    "qpu_count = target.num_qpus()\n",
    "print(\"Number of QPUs:\", qpu_count)\n",
    "\n",
    "qubit_count = 10\n",
    "sample_count = 10000\n",
    "\n",
    "ham = spin.z(0)\n",
    "\n",
    "parameter_count = 3*qubit_count\n",
    "\n",
    "# Below we run a circuit for 10000 different input parameters.\n",
    "parameters = np.random.default_rng(13).uniform(low=0,high=1,size=(sample_count,parameter_count))\n",
    "\n",
    "print('Parameter shape: ', parameters.shape)\n",
    "\n",
    "@cudaq.kernel\n",
    "def qnn(theta:list[float]):\n",
    "    qubits = cudaq.qvector(qubit_count)\n",
    "\n",
    "    count=0\n",
    "    for i in range(qubit_count):\n",
    "        u3(theta[count], theta[count+1], theta[count+2], qubits[i])\n",
    "        count+=3\n",
    "    \n",
    "    for i in range(qubit_count-1):\n",
    "        x.ctrl(qubits[i], qubits[i+1])\n",
    "    \n",
    "    x.ctrl(qubits[qubit_count-1], qubits[0])\n",
    "    \n",
    "          \n",
    "# Single-GPU: broadcasting:\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "result = cudaq.observe(qnn, ham, parameters)\n",
    "energies = np.array([r.expectation() for r in result])\n",
    "\n",
    "end_time = timeit.default_timer()\n",
    "print('Elapsed time (s) for single GPU: ', end_time-start_time)\n",
    "\n",
    "#print('Energies from single GPU')\n",
    "#print(energies)\n",
    "\n",
    "\n",
    "# Multi-GPU\n",
    "\n",
    "# We split our parameters into 4 arrays since we have 4 GPUs available.\n",
    "xi = np.split(parameters,4)\n",
    "\n",
    "print('We have', parameters.shape[0],\n",
    "      'parameters which we would like to execute')\n",
    "\n",
    "print('We split this into', len(xi), 'batches of', xi[0].shape[0], ',',\n",
    "      xi[1].shape[0], ',', xi[2].shape[0], ',', xi[3].shape[0])\n",
    "\n",
    "print('Shape after splitting', xi[0].shape)\n",
    "asyncresults = []\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "for i in range(len(xi)):\n",
    "    for j in range(xi[i].shape[0]):\n",
    "        qpu_id = i * 4 // len(xi)\n",
    "        asyncresults.append(\n",
    "            cudaq.observe_async(qnn, ham, xi[i][j, :], qpu_id=qpu_id))\n",
    "\n",
    "#print('Energies from multi-GPUs')\n",
    "for result in asyncresults:\n",
    "    observe_result = result.get()\n",
    "    got_expectation = observe_result.expectation()\n",
    "    #print(got_expectation)\n",
    "end_time = timeit.default_timer()\n",
    "print(f'Elapsed time (s) for multi-QPU with {qpu_count} QPUs is {end_time-start_time}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extend to multi-node multi-GPUs:\n",
    "\n",
    "``` python\n",
    "\n",
    "\n",
    "import cudaq\n",
    "from cudaq import spin\n",
    "import numpy as np\n",
    "import timeit\n",
    "\n",
    "cudaq.mpi.initialize()\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "cudaq.set_target(\"nvidia\", option=\"mqpu\")\n",
    "target = cudaq.get_target()\n",
    "my_qpu_count = target.num_qpus()\n",
    "qpu_count = my_qpu_count * cudaq.mpi.num_ranks()\n",
    "print(f\"My rank {cudaq.mpi.rank()} of {cudaq.mpi.num_ranks()}\")\n",
    "print(\"Number of my QPUs:\", my_qpu_count)\n",
    "print(\"Number of QPUs total:\", qpu_count)\n",
    "\n",
    "qubit_count = 24\n",
    "sample_count = 10000\n",
    "\n",
    "ham = spin.z(0)\n",
    "\n",
    "\n",
    "# Below we run a circuit for 1200 different sets of input parameters.\n",
    "parameters = np.random.default_rng(13).uniform(low=0,high=1,size=(sample_count, qubit_count))\n",
    "\n",
    "print('Parameter shape: ', parameters.shape)\n",
    "\n",
    "@cudaq.kernel\n",
    "def kernel_rx(theta:list[float]):\n",
    "    qubits = cudaq.qvector(qubit_count)\n",
    "\n",
    "    for i in range(qubit_count):\n",
    "        rx(theta[i], qubits)\n",
    "\n",
    "# split per node\n",
    "split_params = np.split(parameters, cudaq.mpi.num_ranks())\n",
    "my_rank_params = split_params[cudaq.mpi.rank()]\n",
    "\n",
    "# Multi-GPU\n",
    "# We split our parameters into per-GPU arrays\n",
    "xi = np.split(my_rank_params, my_qpu_count)\n",
    "\n",
    "print('We have', parameters.shape[0],\n",
    "      'parameter sets which we would like to execute')\n",
    "\n",
    "print('We have', my_rank_params.shape[0],\n",
    "      'parameter sets on this rank')\n",
    "\n",
    "print('Number of param sets on this rank:', len(xi))\n",
    "print('Shape of each parameter set after splitting:', xi[0].shape)\n",
    "asyncresults = []\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "\n",
    "# For each batch\n",
    "for i in range(len(xi)):\n",
    "    # For each parameter set\n",
    "    for j in range(xi[i].shape[0]):\n",
    "        asyncresults.append(\n",
    "            cudaq.observe_async(kernel_rx, ham, xi[i][j], qpu_id=i))\n",
    "\n",
    "\n",
    "\n",
    "exp_list = []\n",
    "for result in asyncresults:\n",
    "    observe_result = result.get() # sync happens here.\n",
    "    got_expectation = observe_result.expectation()\n",
    "    exp_list.append(got_expectation)\n",
    "\n",
    "end_time = timeit.default_timer()\n",
    "\n",
    "print(f'Elapsed time (s) for multi-QPU with {my_qpu_count} QPUs is {end_time-start_time}')\n",
    "print(f\"My rank has {len(exp_list)} results\")\n",
    "total_results = cudaq.mpi.all_gather(len(exp_list)*cudaq.mpi.num_ranks(), exp_list)\n",
    "print(f\"My rank has {len(total_results)} results after all gather\")\n",
    "\n",
    "\n",
    "cudaq.mpi.finalize()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-reference quantum krylov subspace: H2 example\n",
    "\n",
    "Instead of preparing a wavefunction directly on the QC device and measure the energy, we use the  QC device to prepare a simpler pairwise superposition of the state.\n",
    "\n",
    "\n",
    "<div>\n",
    "<img src=\"./mrqks.png\" width=\"600\">\n",
    "</div>\n",
    "\n",
    "<div>\n",
    "<img src=\"./WF-MRQKS.png\" width=\"400\">\n",
    "</div>\n",
    "\n",
    "<div>\n",
    "<img src=\"./ovlp-ham-MRQKS.png\" width=\"500\">\n",
    "<div>\n",
    "\n",
    "<div>\n",
    "<img src=\"./eigval-MRQKS.png\" width=\"300\">\n",
    "<div>\n",
    "\n",
    "To learn more, see this [paper](https://arxiv.org/pdf/1911.05163)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground state energy (classical simulation)=  (-1.1371757102406848+0j) , index=  3\n"
     ]
    }
   ],
   "source": [
    "import cudaq\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "cudaq.set_target(\"nvidia\", option='mqpu,fp64')\n",
    "\n",
    "# Define H2 molecule\n",
    "geometry = [('H', (0.0, 0, 0)), ('H', (0.0, 0.0, 0.7474))]\n",
    "\n",
    "hamiltonian, data = cudaq.chemistry.create_molecular_hamiltonian(\n",
    "    geometry, 'sto-3g', 1, 0)\n",
    "\n",
    "electron_count = data.n_electrons\n",
    "qubits_num = 2 * data.n_orbitals\n",
    "\n",
    "spin_ham_matrix = hamiltonian.to_matrix()\n",
    "e, c = np.linalg.eig(spin_ham_matrix)\n",
    "\n",
    "# Find the ground state energy and the corresponding eigenvector\n",
    "print('Ground state energy (classical simulation)= ', np.min(e), ', index= ',\n",
    "      np.argmin(e))\n",
    "min_indices = np.argmin(e)\n",
    "\n",
    "# Eigen vector can be used to initialize the qubits\n",
    "vec = c[:, min_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect coefficients from a spin operator so we can pass them to a kernel\n",
    "def termCoefficients(ham: cudaq.SpinOperator) -> list[complex]:\n",
    "    result = []\n",
    "    ham.for_each_term(lambda term: result.append(term.get_coefficient()))\n",
    "    return result\n",
    "\n",
    "# Collect Pauli words from a spin operator so we can pass them to a kernel\n",
    "def termWords(ham: cudaq.SpinOperator) -> list[str]:\n",
    "    result = []\n",
    "    ham.for_each_term(lambda term: result.append(term.to_string(False)))\n",
    "    return result\n",
    "\n",
    "\n",
    "coefficient = termCoefficients(hamiltonian)\n",
    "pauli_string = termWords(hamiltonian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cudaq.kernel\n",
    "def U_psi(qubits: cudaq.qview, dt: float, coefficients: list[complex],\n",
    "          words: list[cudaq.pauli_word]):\n",
    "    # Compute U_m = exp(-i m dt H)\n",
    "    for i in range(len(coefficients)):\n",
    "        exp_pauli(dt * coefficients[i].real, qubits, words[i])\n",
    "\n",
    "\n",
    "@cudaq.kernel\n",
    "def U_phi(qubits: cudaq.qview, dt: float, coefficients: list[complex],\n",
    "          words: list[cudaq.pauli_word]):\n",
    "    # Compute U_n = exp(-i n dt H)\n",
    "    for i in range(len(coefficients)):\n",
    "        exp_pauli(dt * coefficients[i].real, qubits, words[i])\n",
    "\n",
    "\n",
    "@cudaq.kernel\n",
    "def apply_pauli(qubits: cudaq.qview, word: list[int]):\n",
    "\n",
    "    # Add H (Hamiltonian operator)\n",
    "    for i in range(len(word)):\n",
    "        if word[i] == 1:\n",
    "            x(qubits[i])\n",
    "        if word[i] == 2:\n",
    "            y(qubits[i])\n",
    "        if word[i] == 3:\n",
    "            z(qubits[i])\n",
    "\n",
    "\n",
    "@cudaq.kernel\n",
    "def qfd_kernel(dt_alpha: float, dt_beta: float, coefficients: list[complex],\n",
    "               words: list[cudaq.pauli_word], word_list: list[int],\n",
    "               vec: list[complex]):\n",
    "\n",
    "    ancilla = cudaq.qubit()\n",
    "    qreg = cudaq.qvector(vec)\n",
    "\n",
    "    h(ancilla)\n",
    "\n",
    "    x(ancilla)\n",
    "    cudaq.control(U_psi, ancilla, qreg, dt_alpha, coefficients, words)\n",
    "    x(ancilla)\n",
    "\n",
    "    cudaq.control(apply_pauli, ancilla, qreg, word_list)\n",
    "    cudaq.control(U_phi, ancilla, qreg, dt_beta, coefficients, words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pauli_str(pauli_word, qubits_num):\n",
    "\n",
    "    my_list = []\n",
    "    for i in range(qubits_num):\n",
    "        if str(pauli_word[i]) == 'I':\n",
    "            my_list.append(0)\n",
    "        if str(pauli_word[i]) == 'X':\n",
    "            my_list.append(1)\n",
    "        if str(pauli_word[i]) == 'Y':\n",
    "            my_list.append(2)\n",
    "        if str(pauli_word[i]) == 'Z':\n",
    "            my_list.append(3)\n",
    "    return my_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the spin-op x for real component and y for the imaginary component.\n",
    "\n",
    "x_0 = cudaq.spin.x(0)\n",
    "y_0 = cudaq.spin.y(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define parameters for the quantum Krylov space\n",
    "\n",
    "dt = 0.5\n",
    "\n",
    "# Dimension of the Krylov space\n",
    "m_qfd = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the basis overlap matrix\n",
    "\n",
    "# Add identity operator to compute overlap of basis\n",
    "\n",
    "observe_op = 1.0\n",
    "for m in range(qubits_num):\n",
    "    observe_op *= cudaq.spin.i(m)\n",
    "\n",
    "identity_word = observe_op.to_string(False)\n",
    "\n",
    "pauli_list = pauli_str(identity_word, qubits_num)\n",
    "#print(pauli_list)\n",
    "\n",
    "wf_overlap = np.zeros((m_qfd, m_qfd), dtype=complex)\n",
    "\n",
    "collect_overlap_real=[]\n",
    "collect_overlap_img=[]\n",
    "\n",
    "count=0\n",
    "for m in range(m_qfd):\n",
    "    dt_m = dt * m\n",
    "    for n in range(m, m_qfd):\n",
    "        dt_n = dt * n\n",
    "        \n",
    "        count_id=count%2\n",
    "        #print(count_id)\n",
    "        collect_overlap_real.append(cudaq.observe_async(qfd_kernel, x_0, dt_m, dt_n,\n",
    "                                coefficient, pauli_string, pauli_list, vec, qpu_id=count_id))\n",
    "        \n",
    "        collect_overlap_img.append(cudaq.observe_async(qfd_kernel, y_0, dt_m, dt_n,\n",
    "                                coefficient, pauli_string, pauli_list, vec, qpu_id=count_id+2))\n",
    "        count+=1\n",
    "\n",
    "tot_dim=0\n",
    "\n",
    "for n in range(m_qfd):\n",
    "    for m in range(n,m_qfd):\n",
    "        observe_result = collect_overlap_real[tot_dim].get()\n",
    "        real_val = observe_result.expectation()  \n",
    "    \n",
    "        observe_result=collect_overlap_img[tot_dim].get()\n",
    "        img_val=observe_result.expectation() \n",
    "    \n",
    "        wf_overlap[m, n] = real_val + img_val * 1j\n",
    "        if n != m:\n",
    "            wf_overlap[n, m] = np.conj(wf_overlap[m, n])\n",
    "        \n",
    "        tot_dim+=1\n",
    "\n",
    "#print(wf_overlap)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the matrix Hamiltonian\n",
    "\n",
    "\n",
    "ham_matrx = np.zeros((m_qfd, m_qfd), dtype=complex)\n",
    "\n",
    "\n",
    "for m in range(m_qfd):\n",
    "    dt_m = dt * m\n",
    "    for n in range(m, m_qfd):\n",
    "        dt_n = dt * n\n",
    "\n",
    "        ham_matrix_real=[]\n",
    "        ham_matrix_imag=[]\n",
    "        \n",
    "        count=0\n",
    "        tot_e = np.zeros(2)\n",
    "        for coef, word in zip(coefficient, pauli_string):\n",
    "            count_id=count%2\n",
    "            #print(coef,word)\n",
    "\n",
    "            pauli_list = pauli_str(word, qubits_num)\n",
    "            #print(pauli_list)\n",
    "\n",
    "            ham_matrix_real.append(cudaq.observe_async(qfd_kernel, x_0, dt_m, dt_n,\n",
    "                                    coefficient, pauli_string, pauli_list, vec, qpu_id=count_id))\n",
    "            ham_matrix_imag.append(cudaq.observe_async(qfd_kernel, y_0, dt_m, dt_n,\n",
    "                                    coefficient, pauli_string, pauli_list, vec, qpu_id=count_id+2))\n",
    "\n",
    "            count+=1\n",
    "        \n",
    "        i=0\n",
    "        for coef in coefficient:\n",
    "            \n",
    "            observe_result = ham_matrix_real[i].get()\n",
    "            real_val = observe_result.expectation()  \n",
    "    \n",
    "            observe_result=ham_matrix_imag[i].get()\n",
    "            img_val=observe_result.expectation() \n",
    "            \n",
    "            tot_e[0] += real_val * coef.real \n",
    "            tot_e[1] += img_val * coef.imag\n",
    "            \n",
    "            i+=1\n",
    "        \n",
    "        ham_matrx[m, n] = tot_e[0] + tot_e[1] * 1j\n",
    "        if n != m:\n",
    "            ham_matrx[n, m] = np.conj(ham_matrx[m, n])\n",
    "\n",
    "#print(ham_matrx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagonalize the matrix\n",
    "\n",
    "\n",
    "def eig(H, s):\n",
    "    #Solver for generalized eigenvalue problem\n",
    "\n",
    "    # HC = SCE\n",
    "\n",
    "    THRESHOLD = 1e-20\n",
    "    s_diag, u = scipy.linalg.eig(s)\n",
    "    s_prime = []\n",
    "    for sii in s_diag:\n",
    "        if np.imag(sii) > 1e-7:\n",
    "            raise ValueError(\n",
    "                \"S may not be hermitian, large imag. eval component.\")\n",
    "        if np.real(sii) > THRESHOLD:\n",
    "            s_prime.append(np.real(sii))\n",
    "\n",
    "    X_prime = np.zeros((len(s_diag), len(s_prime)), dtype=complex)\n",
    "\n",
    "    for i in range(len(s_diag)):\n",
    "        for j in range(len(s_prime)):\n",
    "            X_prime[i][j] = u[i][j] / np.sqrt(s_prime[j])\n",
    "\n",
    "    H_prime = (((X_prime.conjugate()).transpose()).dot(H)).dot(X_prime)\n",
    "    e_prime, C_prime = scipy.linalg.eig(H_prime)\n",
    "    C = X_prime.dot(C_prime)\n",
    "\n",
    "    return e_prime, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energy from QFD:\n",
      "(-1.136753643031334+2.056438073599281e-19j)\n"
     ]
    }
   ],
   "source": [
    "eigen_value, eigen_vect = eig(ham_matrx[0:m_qfd, 0:m_qfd], wf_overlap[0:m_qfd,0:m_qfd])\n",
    "print('Energy from QFD:')\n",
    "print(np.min(eigen_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parallel with parameter shift gradient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of terms in the spin hamiltonian:  62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_49645/1775979460.py:28: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  spin_ham=cudaq.SpinOperator(qubit_hamiltonian)\n"
     ]
    }
   ],
   "source": [
    "import openfermion\n",
    "import openfermionpyscf\n",
    "from openfermion.transforms import jordan_wigner, get_fermion_operator\n",
    "\n",
    "import cudaq\n",
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "\n",
    "# GPU\n",
    "cudaq.set_target(\"nvidia\", option=\"fp64\")\n",
    "\n",
    "# 1- Classical pre-processing:\n",
    "geometry=[('O', (0.1173,0.0,0.0)), ('H', (-0.4691,0.7570,0.0)), ('H', (-0.4691,-0.7570,0.0))]\n",
    "basis='sto3g'\n",
    "multiplicity=1\n",
    "charge=0\n",
    "ncore=3\n",
    "norb_cas, nele_cas = (3,4)\n",
    "\n",
    "molecule = openfermionpyscf.run_pyscf(openfermion.MolecularData(geometry, basis, multiplicity,charge))\n",
    "\n",
    "molecular_hamiltonian = molecule.get_molecular_hamiltonian(\n",
    "        occupied_indices=range(ncore), active_indices=range(ncore,ncore+norb_cas))\n",
    "\n",
    "fermion_hamiltonian = get_fermion_operator(molecular_hamiltonian)\n",
    "qubit_hamiltonian = jordan_wigner(fermion_hamiltonian)\n",
    "\n",
    "spin_ham=cudaq.SpinOperator(qubit_hamiltonian)\n",
    "print('Total number of terms in the spin hamiltonian: ',spin_ham.get_term_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2- Quantum computing using UCCSD ansatz\n",
    "electron_count=nele_cas\n",
    "qubit_count=2*norb_cas\n",
    "\n",
    "@cudaq.kernel\n",
    "def kernel(qubit_num:int, electron_num:int, thetas: list[float]):\n",
    "        qubits = cudaq.qvector(qubit_num)\n",
    "\n",
    "        for i in range(electron_num):\n",
    "                x(qubits[i])\n",
    "\n",
    "        cudaq.kernels.uccsd(qubits, thetas, electron_num, qubit_num)\n",
    "\n",
    "parameter_count = cudaq.kernels.uccsd_num_parameters(electron_count,qubit_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(42)\n",
    "x0 = np.random.normal(0, 1, parameter_count)\n",
    "\n",
    "cudaq.set_target(\"nvidia\", option='mqpu,fp64')\n",
    "\n",
    "num_qpus = 4\n",
    "\n",
    "epsilon =np.pi/4\n",
    "def batched_gradient_function(kernel, parameters, hamiltonian, epsilon): \n",
    "\n",
    "\n",
    "    x = np.tile(parameters, (len(parameters),1))\n",
    "\n",
    "    xplus = x + (np.eye(x.shape[0]) * epsilon)\n",
    "\n",
    "    xminus = x - (np.eye(x.shape[0]) * epsilon)\n",
    "\n",
    "    g_plus = []\n",
    "    g_minus = []\n",
    "    gradients = []\n",
    "\n",
    "    qpu_counter = 0 # Iterate over the number of GPU resources available\n",
    "    for i in range(x.shape[0]): \n",
    "\n",
    "        g_plus.append(cudaq.observe_async(kernel,hamiltonian, qubit_count, electron_count, xplus[i], qpu_id = qpu_counter))\n",
    "        qpu_counter += 1 \n",
    "\n",
    "        g_minus.append(cudaq.observe_async(kernel, hamiltonian, qubit_count, electron_count, xminus[i], qpu_id = qpu_counter))\n",
    "        qpu_counter += 1 \n",
    "        \n",
    "        if qpu_counter%num_qpus == 0: \n",
    "            qpu_counter = 0 \n",
    "        \n",
    "    gradients = [(g_plus[i].get().expectation() - g_minus[i].get().expectation()) / (2*epsilon) for i in range(len(g_minus))]\n",
    "\n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient = batched_gradient_function(kernel, x0, spin_ham, epsilon)\n",
    "\n",
    "exp_vals=[]\n",
    "\n",
    "def objective_function(parameter_vector: list[float], hamiltonian=spin_ham, kernel=kernel):\n",
    "\n",
    "\n",
    "    get_result = lambda parameter_vector: cudaq.observe\\\n",
    "        (kernel, hamiltonian, qubit_count, electron_count, parameter_vector).expectation()\n",
    "    \n",
    "    cost = get_result(parameter_vector)\n",
    "    exp_vals.append(cost)\n",
    "    gradient_vector = batched_gradient_function(kernel, parameter_vector, spin_ham, epsilon)\n",
    "    \n",
    "    return cost , gradient_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VQE-UCCSD energy=  -74.96736977140642\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "init_params = np.random.normal(0, 1, parameter_count)\n",
    "\n",
    "result_vqe=minimize(objective_function,init_params, method='L-BFGS-B', jac=True, tol=1e-8, options={'maxiter': 10})\n",
    "\n",
    "print('VQE-UCCSD energy= ', result_vqe.fun)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(exp_vals)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Energy')\n",
    "plt.title('VQE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Batch the Spin Hamiltonia terms:\n",
    "\n",
    "<div>\n",
    "<img src=\"./ham-batch.png\" width=\"600\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time (s) for single-GPU:  2.3234453659970313\n",
      "Elapsed time (s) for multi-GPU:  4.76827342499746\n"
     ]
    }
   ],
   "source": [
    "import cudaq\n",
    "from cudaq import spin\n",
    "\n",
    "import timeit\n",
    "\n",
    "cudaq.set_target(\"nvidia\", option=\"mqpu\")\n",
    "\n",
    "#cudaq.mpi.initialize()\n",
    "\n",
    "qubit_count = 22\n",
    "term_count = 100000\n",
    "\n",
    "@cudaq.kernel\n",
    "def batch_ham():\n",
    "    qubits=cudaq.qvector(qubit_count)\n",
    "    h(qubits[0])\n",
    "    for i in range(1, qubit_count):\n",
    "        x.ctrl(qubits[0], qubits[i])\n",
    "\n",
    "# We create a random Hamiltonian\n",
    "hamiltonian = cudaq.SpinOperator.random(qubit_count, term_count)\n",
    "\n",
    "# The observe calls allows us to calculate the expectation value of the Hamiltonian with respect to a specified kernel.\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "# Single node, single GPU.\n",
    "result = cudaq.observe(batch_ham, hamiltonian).expectation()\n",
    "end_time = timeit.default_timer()\n",
    "print('Elapsed time (s) for single-GPU: ', end_time-start_time)\n",
    "\n",
    "# If we have multiple GPUs/ QPUs available, we can parallelize the workflow with the addition of an argument in the observe call.\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "# Single node, multi-GPU.\n",
    "result = cudaq.observe(batch_ham, hamiltonian, execution=cudaq.parallel.thread).expectation()\n",
    "end_time = timeit.default_timer()\n",
    "print('Elapsed time (s) for multi-GPU: ', end_time-start_time)\n",
    "\n",
    "\n",
    "# Multi-node, multi-GPU. (if included use mpirun -np n filename.py)\n",
    "#result = cudaq.observe(batch_ham, hamiltonian, execution=cudaq.parallel.mpi).expectation()\n",
    "\n",
    "#cudaq.mpi.finalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3- Multi-GPU and scaling\n",
    "\n",
    "The multi-GPU NVIDIA target (`mgpu` option) backend is useful for running a large single quantum circuit spread across multiple GPUs.\n",
    "\n",
    "- A $n$ qubit quantum state has $2^n$ complex amplitudes, each of which require 8 bytes of memory to store. Hence the total memory required to store a n qubit quantum state is $8$ bytes $\\times 2^n$. For $n=30$ qubits, this is roughly $8$ GB but for $n=40$, this exponentially increases to $8700$ GB.\n",
    "\n",
    "- For instance, a 3-qubit system with 8 state vector elements can be equally distributed to 4 GPUs as described in the following figure.\n",
    "\n",
    "<div>\n",
    "<img src=\"./sv-parallel.png\" width=\"400\">\n",
    "</div>\n",
    "\n",
    "#### Example: GHZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "# mpirun -np 4 python <fname> --target nvidia --target-option mgpu\n",
    "\n",
    "import cudaq\n",
    "\n",
    "cudaq.mpi.initialize()\n",
    "\n",
    "qubit_count = 30\n",
    "\n",
    "@cudaq.kernel\n",
    "def kernel(qubit_num: int):\n",
    "    # Allocate our qubits.\n",
    "    qvector = cudaq.qvector(qubit_num)\n",
    "    # Place the first qubit in the superposition state.\n",
    "    h(qvector[0])\n",
    "    # Loop through the allocated qubits and apply controlled-X,\n",
    "    # or CNOT, operations between them.\n",
    "    for qubit in range(qubit_num - 1):\n",
    "        x.ctrl(qvector[qubit], qvector[qubit + 1])\n",
    "    # Measure the qubits.\n",
    "    mz(qvector)\n",
    "\n",
    "#print(\"Preparing GHZ state for\", qubit_count, \"qubits.\")\n",
    "counts = cudaq.sample(kernel, qubit_count)\n",
    "\n",
    "if cudaq.mpi.rank() == 0:\n",
    "    print(counts)\n",
    "\n",
    "cudaq.mpi.finalize()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 000000000000000000000000000000:513 111111111111111111111111111111:487 }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mpirun -np 4 python ghz.py --target nvidia --target-option mgpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4- Remote-mQPU:\n",
    "\n",
    "<div>\n",
    "<img src=\"./remote-mqpu.png\" width=\"700\">\n",
    "</div>\n",
    "\n",
    "the multi-QPU NVIDIA platform enables multi-QPU distribution whereby each QPU is simulated by a single NVIDIA GPU. To run multi-QPU workloads on different simulator backends, one can use the remote-mqpu platform, which encapsulates simulated QPUs as independent HTTP REST server instances.\n",
    "\n",
    "By default, auto launching daemon services do not support MPI parallelism. Hence, using the nvidia-mgpu backend to simulate each virtual QPU requires manually launching each server instance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "\n",
    "CUDA_VISIBLE_DEVICES=0,1 mpiexec -np 2 python3 cudaq-qpud --port <QPU 1 TCP/IP port number>\n",
    "CUDA_VISIBLE_DEVICES=2,3 mpiexec -np 2 python3 cudaq-qpud --port <QPU 2 TCP/IP port number>\n",
    "CUDA_VISIBLE_DEVICES=4,5 mpiexec -np 2 python3 cudaq-qpud --port <QPU 3 TCP/IP port number>\n",
    "CUDA_VISIBLE_DEVICES=6,7 mpiexec -np 2 python3 cudaq-qpud --port <QPU 4 TCP/IP port number>\n",
    "```\n",
    "\n",
    "```<QPU n TCP/IP port number>```: The network ports just need to be available, so you can pick random numbers between ~1100 and ~49000.\n",
    "\n",
    "Note: If the port is unavailable, it will report an error saying something like \"failed to bind to port\"\n",
    "\n",
    "Note: When you are done with the servers, you need to manually kill them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "\n",
    "import cudaq\n",
    "from cudaq import spin\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "backend = 'nvidia-mgpu'\n",
    "servers = \"localhost:30001,localhost:30002\"\n",
    "\n",
    "# Set the target to execute on and query the number of QPUs in the system;\n",
    "# The number of QPUs is equal to the number of (auto-)launched server instances.\n",
    "cudaq.set_target(\"remote-mqpu\",\n",
    "                    backend=backend,\n",
    "                    auto_launch=str(servers) if servers.isdigit() else \"\",\n",
    "                    url=\"\" if servers.isdigit() else servers)\n",
    "qpu_count = cudaq.get_target().num_qpus()\n",
    "print(\"Number of virtual QPUs:\", qpu_count)\n",
    "\n",
    "qubit_count = 30\n",
    "sample_count = 2\n",
    "\n",
    "ham = spin.z(0)\n",
    "\n",
    "parameter_count = qubit_count\n",
    "\n",
    "# Below we run a circuit for 500 different input parameters.\n",
    "parameters = np.random.default_rng(13).uniform(low=0,high=1,size=(sample_count,parameter_count))\n",
    "\n",
    "print('Parameter shape: ', parameters.shape)\n",
    "\n",
    "@cudaq.kernel\n",
    "def kernel_rx(theta:list[float]):\n",
    "    qubits = cudaq.qvector(qubit_count)\n",
    "\n",
    "    for i in range(qubit_count):\n",
    "        rx(theta[i], qubits)\n",
    "\n",
    "# Multi-GPU\n",
    "\n",
    "# We split our parameters into 2 arrays \n",
    "xi = np.split(parameters,2)\n",
    "\n",
    "print('We have', parameters.shape[0],\n",
    "      'parameters which we would like to execute')\n",
    "\n",
    "print('We split this into', len(xi), 'batches of', xi[0].shape[0], ',',\n",
    "      xi[1].shape[0])\n",
    "\n",
    "print('Shape after splitting', xi[0].shape)\n",
    "asyncresults = []\n",
    "\n",
    "\n",
    "for i in range(len(xi)):\n",
    "    for j in range(xi[i].shape[0]):\n",
    "        asyncresults.append(\n",
    "            cudaq.observe_async(kernel_rx, ham, xi[i][j, :], qpu_id=i))\n",
    "\n",
    "\n",
    "print('Energies from multi-GPUs')\n",
    "for result in asyncresults:\n",
    "    observe_result = result.get()\n",
    "    got_expectation = observe_result.expectation()\n",
    "    print(got_expectation)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To execute this job, use:\n",
    "\n",
    "``` python\n",
    "CUDA_VISIBLE_DEVICES=0,1 mpiexec -np 2 cudaq-qpud --port 30001 &\n",
    "\n",
    "CUDA_VISIBLE_DEVICES=2,3 mpiexec -np 2 cudaq-qpud --port 30002 &\n",
    "\n",
    "python3 observe-qml-remote-mqpu.py\n",
    "\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "``` python\n",
    "\n",
    "Number of virtual QPUs: 2\n",
    "Parameter shape:  (2, 30)\n",
    "We have 2 parameters which we would like to execute\n",
    "We split this into 2 batches of 1 , 1\n",
    "Shape after splitting (1, 30)\n",
    "Energies from multi-GPUs\n",
    "-0.17012869483974752\n",
    "-0.9906678983711331\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "\n",
    "cudaq.set_target(\"remote-mqpu\",\n",
    "                    backend=backend,\n",
    "                    auto_launch=str(servers) if servers.isdigit() else \"\",\n",
    "                    url=\"\" if servers.isdigit() else servers)\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "If the use case is simple enough, then the CUDA-Q runtime can auto-launch the server for you. For example, if servers is '2', then auto_launch='2' and url=''. The CUDA-Q runtime will interpret that to mean that it should auto-launch 2 servers and it will auto-pick the ports, so the user doesn't need to specify the URL.\n",
    "\n",
    "But if servers is a comma-separated list of servers (like 'localhost:30001,localhost:30002' ), then auto_launch='' and url='localhost:30001,localhost:30002' . That means the CUDA-Q runtime WON'T auto launch the servers and will use the provided url to connect to when submitting programs to the backend."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
