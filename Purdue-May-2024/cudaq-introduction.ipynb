{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Agenda\n",
    "\n",
    "### A- Introduction to QC and CUDA-Q platform\n",
    "\n",
    "- Installation of CUDA-Q\n",
    "\n",
    "### B- Quantum Circuit Basics\n",
    "\n",
    "B.1- Qubit allocation\n",
    "\n",
    "B.2- Quantum gates\n",
    "\n",
    "B.3- Quantum kernel\n",
    "\n",
    "B.4- Backends & running CUDA-Q programs\n",
    "\n",
    "B.5- Examples\n",
    "\n",
    "### C- Quantum algorithmic primitives\n",
    "\n",
    "C.1- cudaq.sample()\n",
    "\n",
    "- Mid-circuit measurement & conditional sampling\n",
    "\n",
    "C.2- cudaq.observe()\n",
    "\n",
    "- Spin Hamiltonian operator\n",
    "\n",
    "### D- Parameterized Circuit\n",
    "\n",
    "### E- Variational Quantum Algorithm\n",
    "\n",
    "### F- Multi-QPUs and Multi-GPUs\n",
    "\n",
    "### G- Advanced Examples\n",
    "\n",
    "![img](./frame.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A- Introduction to QC and CUDA-Q platform\n",
    "\n",
    "- #### Some basics: to review basics of quantum computing and the linear algebra needed for this tutorial, see (QC-intro.pdf)\n",
    "\n",
    "- #### CUDA-Q stack\n",
    "\n",
    "![img](./CUDA-Q.png)\n",
    "\n",
    "- Single-source Python and C++ programming model\n",
    "- High performance compiler for hybrid GPU/CPU/QPU systems\n",
    "- QPU agnostic - works with any type of QPU, emulated or physical\n",
    "- Supports both state-vector and tensor network backend: backends are optimized for NVIDIA GPUs, including multi-GPU, multi-node support for HPC.\n",
    "\n",
    "#### CUDA-Q performance\n",
    "- NVIDIA CUDA-Q can significantly speed up quantum algorithms, compared to other quantum frameworks. Quantum algorithms can achieve a speedup of up to 2500X over CPU, scaling number of qubits using multiple GPUs.\n",
    "\n",
    "![img](./QML-perfo.png)\n",
    "\n",
    "#### Installation of CUDA-Q: visit [CUDA-Q installation](https://nvidia.github.io/cuda-quantum/latest/using/install/install.html)\n",
    "\n",
    "To explore more, visit this [web page](https://developer.nvidia.com/cuda-q), [GitHub](https://github.com/NVIDIA/cuda-quantum), [documentation](https://nvidia.github.io/cuda-quantum/latest/#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B- Quantum circuit basics\n",
    "\n",
    "![img](./basic-circuit.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### B.1- Qubit allocation\n",
    "\n",
    "- cudaq.qubit(): a single quantum bit (2-level) in the discrete quantum memory space. \n",
    "\n",
    "```qubit=cudaq.qubit()```\n",
    "\n",
    "- cudaq.qvector(N): a multi quantum bit ($2^N$ level) in the discrete quantum memory\n",
    "\n",
    "```qubits=cudaq.qvector(N)```\n",
    "\n",
    "    \n",
    "- Is initialized to the |0> computational basis state.\n",
    "\n",
    "- Owns the quantum memory, therefore it cannot be copied or moved (no-cloning theorem). It can be passed by reference (i.e., references to qubit vectors).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.2- Quantum gates\n",
    "\n",
    "\n",
    "- x: Not gate (Pauli-X gate)\n",
    "\n",
    "```python\n",
    "q=cudaq.qubit()\n",
    "x(q)\n",
    "```\n",
    "- h: Hadamard gate\n",
    "\n",
    "```python\n",
    "q=cudaq.qvector(2)\n",
    "h(q[0])\n",
    "```\n",
    "\n",
    "- x.ctrl(control,target) or ([control_1, control_2], target): C-NOT gate\n",
    "\n",
    "```python\n",
    "q=cudaq.qvector(3)\n",
    "x.ctrl(q[0],q[1])\n",
    "```\n",
    "\n",
    "- rx(angle, qubit): rotation around x-axis\n",
    "```python\n",
    "q=cudaq.qubit()\n",
    "rx(np.pi,q)\n",
    "```\n",
    "\n",
    "- adj: adjoint transformation\n",
    "```python\n",
    "q=cudaq.qubit()\n",
    "rx(np.pi,q)\n",
    "rx.adj(np.pi,q)\n",
    "```\n",
    "\n",
    "- mz: measure qubits in the computational basis\n",
    "\n",
    "```python\n",
    "q=cudaq.qvector(2)\n",
    "h(q[0])\n",
    "x.ctrl(q[0],q[1])\n",
    "mz(q)\n",
    "```\n",
    "\n",
    "\n",
    "To learn more about the quantum operations available in CUDA-Q, visit [this page](https://nvidia.github.io/cuda-quantum/latest/specification/cudaq/kernels.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.3- Quantum kernel\n",
    "\n",
    "- To differentiate between host and quantum device code, the CUDA-Q programming model defines the concept of a quantum kernel.\n",
    "\n",
    "- All quantum kernels must be annotated to indicate they are to be compiled for, and executed on, a specified quantum coprocessor. \n",
    "\n",
    "- Other language bindings may opt to use other language features to enable function annotation or decoration (e.g. a `@cudaq.kernel()` function decorator in Python and `__qpu__` in C++).\n",
    "\n",
    "- Quantum kernel can take classical data as input\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "@cudaq.kernel()\n",
    "def my_first_entry_point_kernel(x : float):\n",
    "   ... quantum code ... \n",
    "\n",
    "@cudaq.kernel()\n",
    "def my_second_entry_point_kernel(x : float, params : list[float]):\n",
    "   ... quantum code ... \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CUDA-Q kernels can serve as input to other quantum kernels and invoked by kernel function body code.\n",
    "\n",
    "\n",
    "```python\n",
    "@cudaq.kernel()\n",
    "def MyStatePrep(qubits : cudaq.qview):\n",
    "    ... apply state prep operations on qubits ... \n",
    "\n",
    "@cudaq.kernel()\n",
    "def MyGenericAlgorithm(statePrep : typing.Callable[[cudaq.qview], None]):\n",
    "    q = cudaq.qvector(10)\n",
    "    statePrep(q)\n",
    "    ...\n",
    "\n",
    "MyGenericAlgorithm(MyStatePrep)\n",
    "```\n",
    "\n",
    "- ```cudaq.qview()```: a non-owning reference to a subset of the discrete quantum memory space. It does not own its elements and can therefore be passed by value or reference. (see [this page](https://nvidia.github.io/cuda-quantum/latest/specification/cudaq/types.html#quantum-containers))\n",
    "\n",
    "- Vectors inside the quantum kernel can be only constructed with specified size\n",
    "\n",
    "```python\n",
    "@cudaq.kernel\n",
    "def kernel(N : int):\n",
    "\n",
    "   # Not Allowed\n",
    "   # i = []\n",
    "   # i.append(1)\n",
    "\n",
    "   # Allowed\n",
    "   i = [0 for k in range(5)]\n",
    "   j = [0 for _ in range(N)]\n",
    "   i[2] = 3\n",
    "   f = [1., 2., 3.]\n",
    "   k = 0\n",
    "   pi = 3.1415926\n",
    "\n",
    "```\n",
    "\n",
    "- To learn more about the CUDA-Q quantum kernel, visit [this page](https://github.com/NVIDIA/cuda-quantum/blob/main/docs/sphinx/specification/cudaq/kernels.rst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.4- Backends & running CUDA-Q programs\n",
    "\n",
    "Two options:\n",
    "\n",
    "1. Define the target when running the program:\n",
    "``` python3 program.py [...] --target <target_name>```\n",
    "\n",
    "2. Target can be defined in the application code:\n",
    "```cudaq.set_target('target_name')``` . Then, to run the program, drop the target flag: \n",
    "```python3 program.py [...]```\n",
    "\n",
    "What is target_name?\n",
    "\n",
    "1. State vector simulators:\n",
    "    - Single-GPU (Default If an NVIDIA GPU and CUDA runtime libraries are available): ```python3 program.py [...] --target nvidia``` \n",
    "    - Multi-GPUs: ```mpirun -np 2 python3 program.py [...] --target nvidia-mgpu``` \n",
    "2. Tensor network simulator:\n",
    "    - Single-GPU: ```python3 program.py [...] --target tensornet``` \n",
    "    - Multi-GPUs: ```mpirun -np 2 python3 program.py [...] --target tensornet``` \n",
    "3. Matrix Product state:\n",
    "    - Only supports single-GPU simulation: ```python3 program.py [...] --target tensornet-mps``` \n",
    "4. NVIDIA Quantum Cloud\n",
    "    - Run any of the above backends using NVIDIA-provided cloud GPUs (early access only). To learn more, visit [this page](https://www.nvidia.com/en-us/solutions/quantum-computing/cloud/).\n",
    "    - E.g. `cudaq.set_target('nvqc', backend='tensornet')`\n",
    "5. Quantum hardware backend (to learn more, visit [this page](https://nvidia.github.io/cuda-quantum/latest/using/backends/hardware.html)):\n",
    "    - ```cudaq.set_target('QPU_name')```. QPU_name could be `ionq`, `quantinuum`, `iqm`, `oqc`, ...etc.\n",
    "\n",
    "\n",
    "To learn more about CUDA-Q backends, visit [this page](https://nvidia.github.io/cuda-quantum/latest/using/backends/backends.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.5- Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ╭───╮╭───╮╭───╮╭───╮╭───╮╭───╮\n",
      "q0 : ┤ h ├┤ x ├┤ y ├┤ z ├┤ t ├┤ s ├\n",
      "     ╰───╯╰───╯╰───╯╰───╯╰───╯╰───╯\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Single qubit example\n",
    "\n",
    "import cudaq\n",
    "\n",
    "# Set the backend target\n",
    "cudaq.set_target('nvidia')\n",
    "\n",
    "# We begin by defining the `Kernel` that we will construct our\n",
    "# program with.\n",
    "@cudaq.kernel()\n",
    "def first_kernel():\n",
    "    '''\n",
    "    This is our first CUDA-Q kernel.\n",
    "    '''\n",
    "    # Next, we can allocate a single qubit to the kernel via `qubit()`.\n",
    "    qubit = cudaq.qubit()\n",
    "\n",
    "    # Now we can begin adding instructions to apply to this qubit!\n",
    "    # Here we'll just add non-parameterized\n",
    "    # single qubit gate that is supported by CUDA-Q.\n",
    "    h(qubit)\n",
    "    x(qubit)\n",
    "    y(qubit)\n",
    "    z(qubit)\n",
    "    t(qubit)\n",
    "    s(qubit)\n",
    "\n",
    "    # Next, we add a measurement to the kernel so that we can sample\n",
    "    # the measurement results on our simulator!\n",
    "    mz(qubit)\n",
    "\n",
    "print(cudaq.draw(first_kernel))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ╭───╮          ╭───╮\n",
      "q0 : ┤ h ├──●────●──┤ x ├\n",
      "     ╰───╯╭─┴─╮  │  ├───┤\n",
      "q1 : ─────┤ x ├──┼──┤ x ├\n",
      "          ╰───╯╭─┴─╮├───┤\n",
      "q2 : ──────────┤ x ├┤ x ├\n",
      "               ╰───╯╰───╯\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multi-qubit example\n",
    "\n",
    "import cudaq\n",
    "\n",
    "cudaq.set_target('nvidia')\n",
    "\n",
    "@cudaq.kernel\n",
    "def second_kernel(N:int):\n",
    "    qubits=cudaq.qvector(N)\n",
    "\n",
    "    h(qubits[0])\n",
    "    x.ctrl(qubits[0],qubits[1])\n",
    "    x.ctrl(qubits[0],qubits[2])\n",
    "    x(qubits)\n",
    "\n",
    "    mz(qubits)\n",
    "\n",
    "print(cudaq.draw(second_kernel,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          \n",
      "q0 : ──●──\n",
      "       │  \n",
      "q1 : ──●──\n",
      "     ╭─┴─╮\n",
      "q2 : ┤ x ├\n",
      "     ╰───╯\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cudaq\n",
    "\n",
    "cudaq.set_target('nvidia')\n",
    "\n",
    "@cudaq.kernel\n",
    "def bar(N:int):\n",
    "    qubits=cudaq.qvector(N)\n",
    "    # front and back: return a direct refernce \n",
    "    controls = qubits.front(N - 1)\n",
    "    target = qubits.back()\n",
    "    x.ctrl(controls, target)\n",
    "\n",
    "\n",
    "print(cudaq.draw(bar,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C- Quantum Algorithmic Primitives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C.1 cudaq.sample():\n",
    "\n",
    "Sample the state of a given quantum circuit for a specified number of shots (circuit execution)\n",
    "\n",
    "This function takes as input a quantum kernel instance followed by the concrete arguments at which the kernel should be invoked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ╭───╮     \n",
      "q0 : ┤ h ├──●──\n",
      "     ╰───╯╭─┴─╮\n",
      "q1 : ─────┤ x ├\n",
      "          ╰───╯\n",
      "\n",
      "{ 00:4916 11:5084 }\n",
      "\n",
      "Observed: 00, 4916\n",
      "Observed: 11, 5084\n"
     ]
    }
   ],
   "source": [
    "import cudaq\n",
    "\n",
    "cudaq.set_target('nvidia')\n",
    "\n",
    "@cudaq.kernel\n",
    "def bell(N:int):\n",
    "    qubits=cudaq.qvector(N)\n",
    "\n",
    "    h(qubits[0])\n",
    "    x.ctrl(qubits[0], qubits[1])\n",
    "\n",
    "    mz(qubits)\n",
    "\n",
    "print(cudaq.draw(bell,2))\n",
    "# Sample the state generated by bell\n",
    "# shots_count: the number of kernel executions. Default is 1000\n",
    "counts = cudaq.sample(bell, 2, shots_count=10000) \n",
    "\n",
    "# Print to standard out\n",
    "print(counts)\n",
    "\n",
    "# Fine-grained access to the bits and counts \n",
    "for bits, count in counts.items():\n",
    "    print('Observed: {}, {}'.format(bits, count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ╭───╮╭──────────╮               \n",
      "q0 : ┤ h ├┤ ry(0.15) ├──●────●────●──\n",
      "     ├───┤├─────────┬╯  │    │    │  \n",
      "q1 : ┤ h ├┤ ry(1.5) ├───●────●────●──\n",
      "     ├───┤╰─────────╯ ╭─┴─╮  │    │  \n",
      "q2 : ┤ h ├────────────┤ x ├──●────●──\n",
      "     ├───┤            ╰───╯╭─┴─╮╭─┴─╮\n",
      "q3 : ┤ h ├─────────────────┤ x ├┤ x ├\n",
      "     ╰───╯                 ╰───╯╰───╯\n",
      "\n",
      "Result:  { 1000:1 1101:677 0100:523 1011:1 1100:706 0110:530 1111:717 1110:705 1001:1 0101:564 0111:575 }\n",
      "\n",
      "Most probable bit string:  1111\n"
     ]
    }
   ],
   "source": [
    "import cudaq\n",
    "\n",
    "cudaq.set_target('nvidia')\n",
    "\n",
    "@cudaq.kernel\n",
    "def third_example(N:int, theta:list[float]):\n",
    "    qubit=cudaq.qvector(N)\n",
    "\n",
    "    h(qubit)\n",
    "\n",
    "    for i in range(0,N//2):\n",
    "        ry(theta[i],qubit[i])\n",
    "    \n",
    "\n",
    "    x.ctrl([qubit[0],qubit[1]],qubit[2]) #ccx\n",
    "    x.ctrl([qubit[0],qubit[1],qubit[2]],qubit[3]) #cccx\n",
    "    x.ctrl(qubit[0:3],qubit[3]) #cccx using Python slicing syntax\n",
    "\n",
    "    mz(qubit)\n",
    "\n",
    "params=[0.15,1.5]\n",
    "\n",
    "print(cudaq.draw(third_example, 4, params))\n",
    "\n",
    "result=cudaq.sample(third_example, 4, params, shots_count=5000)\n",
    "\n",
    "print('Result: ', result)\n",
    "\n",
    "print('Most probable bit string: ', result.most_probable())   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Mid-circuit measurement & conditional sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ \n",
      "  __global__ : { 100:66 110:934 }\n",
      "   aux : { 1:66 0:934 }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cudaq\n",
    "\n",
    "cudaq.set_target('nvidia')\n",
    "\n",
    "@cudaq.kernel\n",
    "def mid_circuit_m(theta:float):\n",
    "    qubit=cudaq.qvector(2)\n",
    "    ancilla=cudaq.qubit()\n",
    "\n",
    "    ry(theta,ancilla)\n",
    "\n",
    "    aux=mz(ancilla)\n",
    "    if aux:\n",
    "        x(qubit[0])\n",
    "        x(ancilla)\n",
    "    else:\n",
    "        x(qubit[0])\n",
    "        x(qubit[1])\n",
    "    \n",
    "    mz(ancilla)\n",
    "    mz(qubit)\n",
    "\n",
    "angle=0.5\n",
    "result=cudaq.sample(mid_circuit_m, angle)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here, we see that we have measured the ancilla qubit to a register named ```aux```\n",
    "\n",
    "- If any measurements appear in the kernel, then only the measured qubits will appear in the ```__global__``` register, and they will be sorted in qubit allocation order.\n",
    "\n",
    "- To learn more about cudaq.sample(), visit [this page](https://nvidia.github.io/cuda-quantum/latest/specification/cudaq/algorithmic_primitives.html#cudaq-sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C.2 cudaq.observe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A common task in variational algorithms is the computation of the expected value of a given observable with respect to a parameterized quantum circuit (⟨H⟩(𝚹) = ⟨ψ(𝚹)|H|ψ(𝚹)⟩).\n",
    "\n",
    "- The `cudaq.observe()` function is provided to enable one to quickly compute this expectation value via execution of the parameterized quantum circuit\n",
    "\n",
    "- In the example below, the obervable H is $H= 5.907 \\, I - 2.1433 \\, X_0X_1 -2.1433\\, Y_0 Y_1 + 0.21829 \\, Z_0 -6.125\\, Z_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energy is 13.562794135947076\n"
     ]
    }
   ],
   "source": [
    "# The example here shows a simple use case for the `cudaq.observe``\n",
    "# function in computing expected values of provided spin hamiltonian operators.\n",
    "\n",
    "import cudaq\n",
    "from cudaq import spin\n",
    "\n",
    "cudaq.set_target('nvidia')\n",
    "\n",
    "qubit_num=2\n",
    "\n",
    "@cudaq.kernel\n",
    "def init_state(qubits:cudaq.qview):\n",
    "    n=qubits.size()\n",
    "    for i in range(n):\n",
    "        x(qubits[i])\n",
    "\n",
    "@cudaq.kernel\n",
    "def observe_example(theta: float):\n",
    "    qvector = cudaq.qvector(qubit_num)\n",
    "\n",
    "    init_state(qvector)\n",
    "    ry(theta, qvector[1])\n",
    "    x.ctrl(qvector[1], qvector[0])\n",
    "\n",
    "\n",
    "spin_operator = 5.907 - 2.1433 * spin.x(0) * spin.x(1) - 2.1433 * spin.y(\n",
    "    0) * spin.y(1) + .21829 * spin.z(0) - 6.125 * spin.z(1)\n",
    "\n",
    "# Pre-computed angle that minimizes the energy expectation of the `spin_operator`.\n",
    "angle = 0.59\n",
    "\n",
    "energy = cudaq.observe(observe_example, spin_operator, angle).expectation()\n",
    "print(f\"Energy is {energy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spin Hamiltonian operator\n",
    "\n",
    "CUDA-Q defines convenience functions in `cudaq.spin` namespace that produce the primitive X, Y, and Z Pauli operators on specified qubit indices which can subsequently be used in algebraic expressions to build up more complicated Pauli tensor products and their sums.\n",
    "\n",
    "$H= 5.907 \\, I - 2.1433 \\, X_0X_1 -2.1433\\, Y_0 Y_1 + 0.21829 \\, Z_0 -6.125\\, Z_1$\n",
    "\n",
    "```python\n",
    "spin_operator = 5.907 - 2.1433 * spin.x(0) * spin.x(1) - 2.1433 * spin.y(\n",
    "    0) * spin.y(1) + .21829 * spin.z(0) - 6.125 * spin.z(1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2+0j] IZZ\n",
      "[-2+0j] ZZI\n",
      "[1+0j] XYZ\n",
      "[0.5+0j] ZII\n",
      "[1+0j] YII\n",
      "[1+0j] IXI\n",
      "[1+0j] YYI\n",
      "\n",
      "Total number of terms in the spin hamiltonian:  7\n"
     ]
    }
   ],
   "source": [
    "from cudaq import spin\n",
    "\n",
    "hamiltonian = 0.5*spin.z(0) + spin.x(1) + spin.y(0) + spin.y(0) * spin.y(1)+ spin.x(0)*spin.y(1)*spin.z(2)\n",
    "\n",
    "# add some more terms\n",
    "for i in range(2):\n",
    "  hamiltonian += -2.0*spin.z(i)*spin.z(i+1)\n",
    "\n",
    "print(hamiltonian)\n",
    "\n",
    "print('Total number of terms in the spin hamiltonian: ',hamiltonian.get_term_count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D- Parameterized Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ╭───────╮╭───────╮\n",
      "q0 : ┤ rx(0) ├┤ ry(0) ├\n",
      "     ╰───────╯╰───────╯\n",
      "\n",
      "Expectation value of the Hamiltonian:  1.0\n"
     ]
    }
   ],
   "source": [
    "import cudaq\n",
    "from cudaq import spin\n",
    "\n",
    "cudaq.set_target(\"nvidia\")\n",
    "\n",
    "@cudaq.kernel\n",
    "def param_circuit(theta: list[float]):\n",
    "    # Allocate a qubit that is initialised to the |0> state.\n",
    "    qubit = cudaq.qubit()\n",
    "    # Define gates and the qubits they act upon.\n",
    "    rx(theta[0], qubit)\n",
    "    ry(theta[1], qubit)\n",
    "\n",
    "\n",
    "# Our hamiltonian will be the Z expectation value of our qubit.\n",
    "hamiltonian = spin.z(0)\n",
    "\n",
    "# Initial gate parameters which initialize the qubit in the zero state\n",
    "parameters = [0.0, 0.0]\n",
    "\n",
    "print(cudaq.draw(param_circuit,parameters))\n",
    "\n",
    "# Compute the expectation value using the initial parameters.\n",
    "expectation_value = cudaq.observe(param_circuit, hamiltonian,parameters).expectation()\n",
    "\n",
    "print('Expectation value of the Hamiltonian: ', expectation_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E- Variational Quantum Algorithm\n",
    "\n",
    "![img](./VQE.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. VQA using ```cudaq.observe()``` & classical optimizer.\n",
    "- Using cudaq built-in optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial cost value:  1.0\n",
      "Initial parameters:  [0.0, 0.0]\n",
      "Final cost value:  -0.9999999999999981\n",
      "Optimized parameters:  [3.141592653589793, 0.0]\n"
     ]
    }
   ],
   "source": [
    "import cudaq\n",
    "from cudaq import spin\n",
    "\n",
    "cudaq.set_target(\"nvidia\")\n",
    "\n",
    "@cudaq.kernel\n",
    "def vqe_circuit(theta: list[float]):\n",
    "    # Allocate a qubit that is initialised to the |0> state.\n",
    "    qubit = cudaq.qubit()\n",
    "    # Define gates and the qubits they act upon.\n",
    "    rx(theta[0], qubit)\n",
    "    ry(theta[1], qubit)\n",
    "\n",
    "\n",
    "# Our hamiltonian will be the Z expectation value of our qubit.\n",
    "hamiltonian = spin.z(0)\n",
    "\n",
    "# Initial gate parameters which initialize the qubit in the zero state\n",
    "initial_param = [0.0, 0.0]\n",
    "\n",
    "cost_values = []\n",
    "\n",
    "def cost(parameters):\n",
    "    \"\"\"Returns the expectation value as our cost.\"\"\"\n",
    "    expectation_value = cudaq.observe(vqe_circuit, hamiltonian, parameters).expectation()\n",
    "    cost_values.append(expectation_value)\n",
    "    return expectation_value\n",
    "\n",
    "initial_cost_value = cost(initial_param)\n",
    "print('Initial cost value: ', initial_cost_value)\n",
    "print('Initial parameters: ', initial_param)\n",
    "\n",
    "# Define a CUDA-Q optimizer.\n",
    "optimizer = cudaq.optimizers.COBYLA()\n",
    "optimizer.initial_parameters = initial_param\n",
    "\n",
    "result = optimizer.optimize(dimensions=2, function=cost)\n",
    "\n",
    "print('Final cost value: ', result[0])\n",
    "print('Optimized parameters: ', result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_values = list(range(len(cost_values)))\n",
    "y_values = cost_values\n",
    "\n",
    "plt.plot(x_values, y_values)\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Cost Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- using third-party optimizer: ex. scipy optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial cost value:  1.0\n",
      "Initial parameters:  [0.0, 0.0]\n",
      "Final cost value:  -0.9999999970938906\n",
      "Optimized parameters:  [3.14159466e+00 1.07798234e-04]\n"
     ]
    }
   ],
   "source": [
    "import cudaq\n",
    "from cudaq import spin\n",
    "import scipy\n",
    "\n",
    "cudaq.set_target(\"nvidia\")\n",
    "\n",
    "@cudaq.kernel\n",
    "def vqe_circuit_scipy(theta: list[float]):\n",
    "    # Allocate a qubit that is initialised to the |0> state.\n",
    "    qubit = cudaq.qubit()\n",
    "    # Define gates and the qubits they act upon.\n",
    "    rx(theta[0], qubit)\n",
    "    ry(theta[1], qubit)\n",
    "\n",
    "\n",
    "# Our hamiltonian will be the Z expectation value of our qubit.\n",
    "hamiltonian = spin.z(0)\n",
    "\n",
    "# Initial gate parameters which initialize the qubit in the zero state\n",
    "initial_parameters = [0.0, 0.0]\n",
    "\n",
    "def cost_scipy(parameters):\n",
    "    \"\"\"Returns the expectation value as our cost.\"\"\"\n",
    "    expectation_value = cudaq.observe(vqe_circuit_scipy, hamiltonian, parameters).expectation()\n",
    "    return expectation_value\n",
    "\n",
    "initial_cost_value = cost_scipy(initial_parameters)\n",
    "print('Initial cost value: ', initial_cost_value)\n",
    "print('Initial parameters: ', initial_parameters)\n",
    "\n",
    "\n",
    "result = scipy.optimize.minimize(cost_scipy,initial_parameters,method='COBYLA')\n",
    "\n",
    "print('Final cost value: ', result.fun)\n",
    "print('Optimized parameters: ', result.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. VQE wrapper: combine ```cudaq.observe()``` and the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "minimized <H> = -0.9999999999999981\n",
      "optimal theta = [3.141592653589793, 0.0]\n"
     ]
    }
   ],
   "source": [
    "import cudaq\n",
    "from cudaq import spin\n",
    "\n",
    "cudaq.set_target(\"nvidia\")\n",
    "\n",
    "@cudaq.kernel\n",
    "def vqe_circuit(theta: list[float]):\n",
    "    # Allocate a qubit that is initialised to the |0> state.\n",
    "    qubit = cudaq.qubit()\n",
    "    # Define gates and the qubits they act upon.\n",
    "    rx(theta[0], qubit)\n",
    "    ry(theta[1], qubit)\n",
    "\n",
    "\n",
    "# Our hamiltonian will be the Z expectation value of our qubit.\n",
    "hamiltonian = spin.z(0)\n",
    "\n",
    "# Initial gate parameters which initialize the qubit in the zero state\n",
    "initial_param = [0.0, 0.0]\n",
    "\n",
    "optimizer = cudaq.optimizers.COBYLA()\n",
    "optimizer.max_iterations = 30\n",
    "optimizer.initial_parameters=initial_param\n",
    "\n",
    "opt_value, opt_theta = cudaq.vqe(kernel=vqe_circuit, \n",
    "                         spin_operator=hamiltonian,\n",
    "                         optimizer=optimizer,\n",
    "                         parameter_count=len(initial_param))\n",
    "\n",
    "print(f\"\\nminimized <H> = {round(opt_value,16)}\")\n",
    "print(f\"optimal theta = {opt_theta}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F- Multi-QPUs and Multi-GPUs\n",
    "\n",
    "#### 1. Multi-QPU (nvidia-mqpu)\n",
    "\n",
    "The `nvidia-mqpu` target is useful for distributing separate quantum circuits to individual GPUs on a single host machine. (For distribution to multiple host machines, see the `remote-mqpu` backend.)\n",
    "\n",
    "![img](./circuit-mqpu.png)\n",
    "\n",
    "- To learn more about `nvidia-mqpu` target, visit [this page](https://nvidia.github.io/cuda-quantum/latest/using/backends/platform.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of QPUs: 5\n",
      "We run two circuits on 2 QPU and the results are: \n",
      "{ 000:282 010:221 111:242 100:256 110:250 001:262 101:242 011:245 }\n",
      "\n",
      "{ 000:237 010:220 111:242 100:287 110:249 001:245 101:275 011:245 }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cudaq\n",
    "\n",
    "cudaq.set_target(\"nvidia-mqpu\")\n",
    "\n",
    "target = cudaq.get_target()\n",
    "qpu_count = target.num_qpus()\n",
    "print(\"Number of QPUs:\", qpu_count)\n",
    "\n",
    "\n",
    "@cudaq.kernel\n",
    "def mqpu_example(qubit_count: int):\n",
    "    qubits = cudaq.qvector(qubit_count)\n",
    "    # Place qubits in superposition state.\n",
    "    h(qubits)\n",
    "    # Measure.\n",
    "    mz(qubits)\n",
    "\n",
    "count_futures = []\n",
    "\n",
    "# We will run on 2 GPUs\n",
    "print('We run two circuits on 2 QPU and the results are: ')\n",
    "for qpu in range(2):\n",
    "    count_futures.append(cudaq.sample_async(mqpu_example, 3, shots_count=2000, qpu_id=qpu))\n",
    "\n",
    "for counts in count_futures:\n",
    "    print(counts.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of QPUs: 5\n",
      "Parameter shape:  (20, 5)\n",
      "Energies from single GPU\n",
      "[0.64879424 0.58455425 0.95929639 0.91762499 0.96933676 0.54637976\n",
      " 0.97521567 0.99867218 0.79019367 0.82274101 0.5851651  0.79346786\n",
      " 0.91356545 0.61507167 0.94903381 0.9993066  0.85096268 0.87421511\n",
      " 0.74546355 0.95660046]\n",
      "We have 20 parameters which we would like to execute\n",
      "We split this into 4 batches of 5 , 5 , 5 , 5\n",
      "Shape after splitting (5, 5)\n",
      "Energies from multi-GPUs\n",
      "0.6487942400292184\n",
      "0.5845542501076578\n",
      "0.9592963923435747\n",
      "0.9176249947660011\n",
      "0.9693367583031431\n",
      "0.5463797623660418\n",
      "0.9752156657889941\n",
      "0.9986721766282083\n",
      "0.790193668694414\n",
      "0.8227410069830512\n",
      "0.5851650997278739\n",
      "0.7934678641667406\n",
      "0.9135654515996343\n",
      "0.615071667695247\n",
      "0.9490338070955175\n",
      "0.9993065973320556\n",
      "0.8509626841137106\n",
      "0.8742151069168358\n",
      "0.7454635462163424\n",
      "0.956600457306422\n"
     ]
    }
   ],
   "source": [
    "import cudaq\n",
    "from cudaq import spin\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "cudaq.set_target(\"nvidia-mqpu\")\n",
    "target = cudaq.get_target()\n",
    "qpu_count = target.num_qpus()\n",
    "print(\"Number of QPUs:\", qpu_count)\n",
    "\n",
    "qubit_count = 5\n",
    "sample_count = 20\n",
    "\n",
    "ham = spin.z(0)\n",
    "\n",
    "parameter_count = qubit_count\n",
    "\n",
    "# Below we run a circuit for 20 different input parameters.\n",
    "parameters = np.random.default_rng(13).uniform(low=0,\n",
    "                                               high=1,\n",
    "                                               size=(sample_count,\n",
    "                                                     parameter_count))\n",
    "\n",
    "print('Parameter shape: ', parameters.shape)\n",
    "\n",
    "@cudaq.kernel\n",
    "def kernel_rx(theta:list[float]):\n",
    "    qubits = cudaq.qvector(qubit_count)\n",
    "\n",
    "    for i in range(qubit_count):\n",
    "        rx(theta[i], qubits[i])\n",
    "\n",
    "#single GPU\n",
    "result = cudaq.observe(kernel_rx, ham, parameters)\n",
    "energies = np.array([r.expectation() for r in result])\n",
    "print('Energies from single GPU')\n",
    "print(energies)\n",
    "\n",
    "# Multi-GPU\n",
    "\n",
    "# We split our parameters into 4 arrays since we have 4 GPUs available.\n",
    "xi = np.split(parameters,4)\n",
    "\n",
    "print('We have', parameters.shape[0],\n",
    "      'parameters which we would like to execute')\n",
    "\n",
    "print('We split this into', len(xi), 'batches of', xi[0].shape[0], ',',\n",
    "      xi[1].shape[0], ',', xi[2].shape[0], ',', xi[3].shape[0])\n",
    "\n",
    "print('Shape after splitting', xi[0].shape)\n",
    "asyncresults = []\n",
    "\n",
    "for i in range(len(xi)):\n",
    "    for j in range(xi[i].shape[0]):\n",
    "        asyncresults.append(\n",
    "            cudaq.observe_async(kernel_rx, ham, xi[i][j, :], qpu_id=i))\n",
    "\n",
    "print('Energies from multi-GPUs')\n",
    "for result in asyncresults:\n",
    "    observe_result = result.get()\n",
    "    got_expectation = observe_result.expectation()\n",
    "    print(got_expectation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Multi-GPU (nvidia-mgpu)\n",
    "\n",
    "The `nvidia-mgpu` backend is useful for running a large single quantum circuit spread across multiple GPUs.\n",
    "- A $n$ qubit quantum state has $2^n$ complex amplitudes, each of which require 8 bytes of memory to store. Hence the total memory required to store a n qubit quantum state is $8$ bytes $\\times 2^n$. For $n=30$ qubits, this is roughly $8$ GB but for $n=40$, this exponentially increases to $8700$ GB.\n",
    "- To learn more about the multi-GPU computation, visit [this page](https://docs.nvidia.com/cuda/cuquantum/latest/custatevec/overview.html#multi-gpu-computation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# mpirun -np 4 python <fname> --target nvidia-mgpu\n",
    "\n",
    "import cudaq\n",
    "\n",
    "cudaq.mpi.initialize()\n",
    "\n",
    "qubit_count = 34\n",
    "\n",
    "@cudaq.kernel\n",
    "def kernel(qubit_count: int):\n",
    "    # Allocate our qubits.\n",
    "    qvector = cudaq.qvector(qubit_count)\n",
    "    # Place the first qubit in the superposition state.\n",
    "    h(qvector[0])\n",
    "    # Loop through the allocated qubits and apply controlled-X,\n",
    "    # or CNOT, operations between them.\n",
    "    for qubit in range(qubit_count - 1):\n",
    "        x.ctrl(qvector[qubit], qvector[qubit + 1])\n",
    "    # Measure the qubits.\n",
    "    mz(qvector)\n",
    "\n",
    "#print(\"Preparing GHZ state for\", qubit_count, \"qubits.\")\n",
    "counts = cudaq.sample(kernel, qubit_count)\n",
    "\n",
    "if cudaq.mpi.rank() == 0:\n",
    "    print(counts)\n",
    "\n",
    "cudaq.mpi.finalize()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G- Advanced Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Observe broadcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.25028963 12.7463697  13.13014707 13.3953207  13.5375372  13.55445895\n",
      " 13.44581138 13.21337514 12.86096912 12.39437941 11.82126641 11.15104264\n",
      " 10.3947097   9.56468975  8.67461104  7.73908823  6.77348197  5.79364859\n",
      "  4.81567611  3.85562305  2.92925391  2.05177916  1.23760717  0.50010619\n",
      " -0.14861362 -0.69790041 -1.13873491 -1.46387879 -1.6679928  -1.74772597\n",
      " -1.70176822 -1.53087529 -1.23785214 -0.82751117 -0.30658954  0.31635915\n",
      "  1.03110573  1.82591505  2.68773578  3.60241499  4.55493715  5.52965962\n",
      "  6.5105773   7.48158647  8.42673803  9.33051716 10.17808243 10.95551597\n",
      " 11.65005271 12.25029037]\n"
     ]
    }
   ],
   "source": [
    "import cudaq\n",
    "\n",
    "cudaq.set_target(\"nvidia\")\n",
    "\n",
    "hamiltonian = 5.907 - 2.1433 * spin.x(0) * spin.x(1) - 2.1433 * spin.y(\n",
    "    0) * spin.y(1) + .21829 * spin.z(0) - 6.125 * spin.z(1)\n",
    "\n",
    "angles = np.linspace(-np.pi, np.pi, 50)\n",
    "\n",
    "#print(angles)\n",
    "qubit_num=2\n",
    "\n",
    "@cudaq.kernel\n",
    "def ansatz_test(angle: float):\n",
    "    q = cudaq.qvector(qubit_num)\n",
    "    x(q[0])\n",
    "    ry(angle, q[1])\n",
    "    x.ctrl(q[1], q[0])\n",
    "\n",
    "results = cudaq.observe(ansatz_test, hamiltonian, angles)\n",
    "energies = np.array([r.expectation() for r in results])\n",
    "print(energies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.        0.0620777]\n"
     ]
    }
   ],
   "source": [
    "import cudaq\n",
    "from cudaq import spin\n",
    "\n",
    "cudaq.set_target(\"nvidia\")\n",
    "\n",
    "@cudaq.kernel\n",
    "def param_circuit(theta: np.ndarray):\n",
    "    # Allocate a qubit that is initialised to the |0> state.\n",
    "    qubit = cudaq.qubit()\n",
    "    # Define gates and the qubits they act upon.\n",
    "    rx(theta[0], qubit)\n",
    "    ry(theta[1], qubit)\n",
    "\n",
    "\n",
    "# Our hamiltonian will be the Z expectation value of our qubit.\n",
    "hamiltonian = spin.z(0)\n",
    "\n",
    "# Initial gate parameters which initialize the qubit in the zero state\n",
    "many_parms = np.array([[0,0],[1.5,0.5]])\n",
    "results= cudaq.observe(param_circuit, hamiltonian, many_parms)\n",
    "energies = np.array([r.expectation() for r in results])\n",
    "print(energies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Pauli word\n",
    "\n",
    "![img](./pauli-word.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expectation value:  0.04777800003152044\n"
     ]
    }
   ],
   "source": [
    "import cudaq\n",
    "from cudaq import spin\n",
    "\n",
    "cudaq.set_target('nvidia')\n",
    "\n",
    "ham=-0.106477- 0.0454063*spin.x(0)*spin.x(1)*spin.y(2)*spin.y(3) +0.174073*spin.z(2\n",
    "                )*spin.z(3)+0.0454063*spin.y(0)*spin.x(1)*spin.x(2)*spin.y(3)\n",
    "\n",
    "\n",
    "@cudaq.kernel\n",
    "def kernel_pauli_word(theta: float, var: cudaq.pauli_word):\n",
    "    q = cudaq.qvector(4)\n",
    "    x(q[0])\n",
    "    x(q[1])\n",
    "    exp_pauli(theta, q, var)\n",
    "\n",
    "exp_val = cudaq.observe(kernel_pauli_word, ham, 0.11, 'XXXY').expectation()\n",
    "\n",
    "print('Expectation value: ', exp_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expectation value:  0.04382123044540878\n"
     ]
    }
   ],
   "source": [
    "import cudaq\n",
    "from cudaq import spin\n",
    "\n",
    "cudaq.set_target('nvidia')\n",
    "\n",
    "ham=-0.106477- 0.0454063*spin.x(0)*spin.x(1)*spin.y(2)*spin.y(3) +0.174073*spin.z(2\n",
    "                )*spin.z(3)+0.0454063*spin.y(0)*spin.x(1)*spin.x(2)*spin.y(3)\n",
    "\n",
    "\n",
    "@cudaq.kernel\n",
    "def kernel_pauli_word_list(theta: float, paulis: list[cudaq.pauli_word]):\n",
    "    q = cudaq.qvector(4)\n",
    "    x(q[0])\n",
    "    x(q[1])\n",
    "    for p in paulis:\n",
    "        exp_pauli(theta, q, p)\n",
    "\n",
    "exp_val = cudaq.observe(kernel_pauli_word_list, ham, 0.11, ['XXXY','XYZY']).expectation()\n",
    "\n",
    "print('Expectation value: ', exp_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Control on kernel function: to learn more, see [this page](https://nvidia.github.io/cuda-quantum/latest/specification/cudaq/synthesis.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 101:1000 }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cudaq\n",
    "\n",
    "cudaq.set_target('nvidia')\n",
    "\n",
    "@cudaq.kernel\n",
    "def fancyCnot(a: cudaq.qubit, b: cudaq.qubit):\n",
    "    x.ctrl(a, b)\n",
    "\n",
    "@cudaq.kernel\n",
    "def toffoli():\n",
    "    q = cudaq.qvector(3)\n",
    "    ctrl = q.front()\n",
    "    # without a control, apply x to all\n",
    "    x(ctrl, q[2])\n",
    "    cudaq.control(fancyCnot, [ctrl], q[1], q[2])\n",
    "\n",
    "counts = cudaq.sample(toffoli)\n",
    "\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. compute_action(): to learn more, visit [this page](https://nvidia.github.io/cuda-quantum/latest/specification/cudaq/patterns.html)\n",
    "\n",
    "- ```compute_action(U,V)```: will invoke $U V U^\\dagger$. $U$ is the compute block and $V$ is the action block.\n",
    "\n",
    "- Example: Grover algorithm: \n",
    "\n",
    "![img](./grover-circuit.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 101:507 011:493 }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cudaq\n",
    "from typing import Callable\n",
    "\n",
    "cudaq.set_target('nvidia')\n",
    "\n",
    "@cudaq.kernel\n",
    "def reflect(qubits: cudaq.qview):\n",
    "    ctrls = qubits.front(qubits.size() - 1)\n",
    "    last = qubits.back()\n",
    "    cudaq.compute_action(lambda: (h(qubits), x(qubits)),\n",
    "                          lambda: z.ctrl(ctrls, last))\n",
    "\n",
    "@cudaq.kernel\n",
    "def oracle(q: cudaq.qview):\n",
    "    z.ctrl(q[0], q[2])\n",
    "    z.ctrl(q[1], q[2])\n",
    "\n",
    "@cudaq.kernel\n",
    "def grover(N: int, M: int, oracle: Callable[[cudaq.qview], None]):\n",
    "    q = cudaq.qvector(N)\n",
    "    h(q)\n",
    "    for i in range(M):\n",
    "        oracle(q)\n",
    "        reflect(q)\n",
    "    mz(q)\n",
    "\n",
    "counts = cudaq.sample(grover, 3, 1, oracle)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. To look at the MLIR and QIR generated from your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module attributes {quake.mangled_name_map = {__nvqpp__mlirgen__kernel = \"__nvqpp__mlirgen__kernel_PyKernelEntryPointRewrite\"}} {\n",
      "  func.func @__nvqpp__mlirgen__kernel(%arg0: i64) attributes {\"cudaq-entrypoint\"} {\n",
      "    %c1_i64 = arith.constant 1 : i64\n",
      "    %c0_i64 = arith.constant 0 : i64\n",
      "    %0 = cc.alloca i64\n",
      "    cc.store %arg0, %0 : !cc.ptr<i64>\n",
      "    %1 = cc.load %0 : !cc.ptr<i64>\n",
      "    %2 = quake.alloca !quake.veq<?>[%1 : i64]\n",
      "    %3 = quake.extract_ref %2[0] : (!quake.veq<?>) -> !quake.ref\n",
      "    quake.h %3 : (!quake.ref) -> ()\n",
      "    %4 = cc.load %0 : !cc.ptr<i64>\n",
      "    %5 = arith.subi %4, %c1_i64 : i64\n",
      "    %6 = cc.loop while ((%arg1 = %c0_i64) -> (i64)) {\n",
      "      %7 = arith.cmpi slt, %arg1, %5 : i64\n",
      "      cc.condition %7(%arg1 : i64)\n",
      "    } do {\n",
      "    ^bb0(%arg1: i64):\n",
      "      %7 = quake.extract_ref %2[%arg1] : (!quake.veq<?>, i64) -> !quake.ref\n",
      "      %8 = arith.addi %arg1, %c1_i64 : i64\n",
      "      %9 = quake.extract_ref %2[%8] : (!quake.veq<?>, i64) -> !quake.ref\n",
      "      quake.x [%7] %9 : (!quake.ref, !quake.ref) -> ()\n",
      "      cc.continue %arg1 : i64\n",
      "    } step {\n",
      "    ^bb0(%arg1: i64):\n",
      "      %7 = arith.addi %arg1, %c1_i64 : i64\n",
      "      cc.continue %7 : i64\n",
      "    } {invariant}\n",
      "    return\n",
      "  }\n",
      "}\n",
      "\n",
      "; ModuleID = 'LLVMDialectModule'\n",
      "source_filename = \"LLVMDialectModule\"\n",
      "\n",
      "%Array = type opaque\n",
      "%Qubit = type opaque\n",
      "\n",
      "declare void @invokeWithControlQubits(i64, void (%Array*, %Qubit*)*, ...) local_unnamed_addr\n",
      "\n",
      "declare void @__quantum__qis__x__ctl(%Array*, %Qubit*)\n",
      "\n",
      "declare void @__quantum__rt__qubit_release_array(%Array*) local_unnamed_addr\n",
      "\n",
      "declare void @__quantum__qis__h(%Qubit*) local_unnamed_addr\n",
      "\n",
      "declare i8* @__quantum__rt__array_get_element_ptr_1d(%Array*, i64) local_unnamed_addr\n",
      "\n",
      "declare %Array* @__quantum__rt__qubit_allocate_array(i64) local_unnamed_addr\n",
      "\n",
      "define void @__nvqpp__mlirgen__kernel(i64 %0) local_unnamed_addr {\n",
      "  %2 = tail call %Array* @__quantum__rt__qubit_allocate_array(i64 %0)\n",
      "  %3 = tail call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %2, i64 0)\n",
      "  %4 = bitcast i8* %3 to %Qubit**\n",
      "  %5 = load %Qubit*, %Qubit** %4, align 8\n",
      "  tail call void @__quantum__qis__h(%Qubit* %5)\n",
      "  %6 = add i64 %0, -1\n",
      "  %7 = icmp sgt i64 %6, 0\n",
      "  br i1 %7, label %.lr.ph, label %._crit_edge\n",
      "\n",
      ".lr.ph:                                           ; preds = %1, %.lr.ph\n",
      "  %8 = phi i64 [ %12, %.lr.ph ], [ 0, %1 ]\n",
      "  %9 = tail call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %2, i64 %8)\n",
      "  %10 = bitcast i8* %9 to %Qubit**\n",
      "  %11 = load %Qubit*, %Qubit** %10, align 8\n",
      "  %12 = add nuw nsw i64 %8, 1\n",
      "  %13 = tail call i8* @__quantum__rt__array_get_element_ptr_1d(%Array* %2, i64 %12)\n",
      "  %14 = bitcast i8* %13 to %Qubit**\n",
      "  %15 = load %Qubit*, %Qubit** %14, align 8\n",
      "  tail call void (i64, void (%Array*, %Qubit*)*, ...) @invokeWithControlQubits(i64 1, void (%Array*, %Qubit*)* nonnull @__quantum__qis__x__ctl, %Qubit* %11, %Qubit* %15)\n",
      "  %16 = icmp slt i64 %12, %6\n",
      "  br i1 %16, label %.lr.ph, label %._crit_edge\n",
      "\n",
      "._crit_edge:                                      ; preds = %.lr.ph, %1\n",
      "  tail call void @__quantum__rt__qubit_release_array(%Array* %2)\n",
      "  ret void\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cudaq\n",
    "\n",
    "cudaq.set_target('nvidia')\n",
    "\n",
    "@cudaq.kernel\n",
    "def kernel(N : int):\n",
    "    q = cudaq.qvector(N)\n",
    "    h(q[0])\n",
    "    for i in range(N-1):\n",
    "        x.ctrl(q[i], q[i+1])\n",
    "\n",
    "# Look at the MLIR \n",
    "print(kernel)\n",
    "\n",
    "# Look at the QIR\n",
    "print(cudaq.to_qir(kernel))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
